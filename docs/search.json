[
  {
    "objectID": "2-searching-data.html",
    "href": "2-searching-data.html",
    "title": "2  Searching Data",
    "section": "",
    "text": "2.1 Task: Write and execute a search query for terms and/or phrases in one or more fields of an index\nThe following section will have only one full example, but will show variations of term and phrase queries. Also, bear in mind that when they say term they may not mean the Elasticsearch use of the word, but rather the generic search use of the word. There are a lot of ways to execute a search in Elasticsearch. Don’t get bogged down; focus on term and phrase searches for this section of the example.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  },
  {
    "objectID": "2-searching-data.html#task-write-and-execute-a-search-query-for-terms-andor-phrases-in-one-or-more-fields-of-an-index",
    "href": "2-searching-data.html#task-write-and-execute-a-search-query-for-terms-andor-phrases-in-one-or-more-fields-of-an-index",
    "title": "2  Searching Data",
    "section": "",
    "text": "Example 1: Write and execute a basic term and phrase search\n\nRequirements\n\nCreate an index\nIndex some documents\nExecute a term query\nExecute a phrase query\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nIndex some documents which will create an index at the same time. The Elastic Console doesn’t like properly formatted documents when calling _bulk so they need to be tightly packed.\nPOST /example_index/_bulk\n{ \"index\": {} }\n{ \"title\": \"The quick brown fox\", \"text\": \"The quick brown fox jumps over the lazy dog.\" }\n{ \"index\": {} }\n{ \"title\": \"Fast and curious\", \"text\": \"A fast and curious fox was seen leaping over a lazy dog.\" }\n{ \"index\": {} }\n{ \"title\": \"A fox in action\", \"text\": \"In a remarkable display of agility, a quick fox effortlessly jumped over a dog.\" }\n{ \"index\": {} }\n{ \"title\": \"Wildlife wonders\", \"text\": \"Observers were amazed as the quick brown fox jumped over the lazy dog.\" }\n{ \"index\": {} }\n{ \"title\": \"Fox tales\", \"text\": \"The tale of the quick fox that jumped over the lazy dog has become a legend.\" }\nExecute a term query\n\n\nUse the GET method to search for documents using 3 different term queries (there are 10 different ways currently. Refer to the Term-level Queries documentation for the full list).\nGET example_index/_search\n{\n  \"query\": {\n    \"term\": {\n      \"title\": {\n        \"value\": \"quick\"\n      }\n    }\n  }\n}\nGET example_index/_search\n{\n  \"query\": {\n    \"terms\": {\n      \"text\": [\"display\", \"amazed\"]\n    }\n  }\n}\n\n\nExecute a phrase query\n\n\nreturns 2 docs\nGET /example_index/_search\n{\n  \"query\": {\n    \"match_phrase\": {\n      \"text\": \"quick brown fox\"\n    }\n  }\n}\nreturns 1 doc\nGET /example_index/_search\n{\n  \"query\": {\n    \"match_phrase_prefix\": {\n      \"text\": \"fast and curi\"\n    }\n  }\n}\nreturns 1 doc\nGET /example_index/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"default_field\": \"text\",\n      \"query\": \"\\\"fox jumps\\\"\"\n    }\n  }\n}\n\n\n\nConsiderations\n\nThe default standard analyzer (lowercasing, whitespace tokenization, basic normalization) is used.\nThe term query is used for exact matches and is not analyzed, meaning it matches the exact term in the inverted index.\nThe match_phrase query analyzes the input text and matches it as a phrase, making it useful for finding exact sequences of terms.\n\n\n\nTest\n\nVerify the various queries return the proper results.\n\n\n\nClean-up (optional)\n\nDelete the example index\nDELETE example_index\n\n\n\nDocumentation\n\nFull Text Queries\nMatch Phrase Query\nMatch Phrase Prefix Query\nQuery DSL\nTerm-level Queries\n\n\n\n\nExample 2: Boosting Document Score When an Additional Field Matches\n\nRequirements\n\nPerform a search for beverage OR bar\nBoost the score of documents if the value snack exists in the tags field.\n\n\n\nSteps\n\nIndex Sample Documents Using _bulk Endpoint:\n\nIndex documents with fields such as name, description, and tags.\n\nPOST /products/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"name\": \"Yoo-hoo Beverage\", \"description\": \"A delicious, chocolate-flavored drink.\", \"tags\": [\"beverage\", \"chocolate\"] }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"name\": \"Apple iPhone 12\", \"description\": \"The latest iPhone model with advanced features.\", \"tags\": [\"electronics\", \"smartphone\"] }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"name\": \"Choco-Lite Bar\", \"description\": \"A light and crispy chocolate snack bar.\", \"tags\": [\"snack\", \"chocolate\"] }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"name\": \"Samsung Galaxy S21\", \"description\": \"A powerful smartphone with an impressive camera.\", \"tags\": [\"electronics\", \"smartphone\"] }\n{ \"index\": { \"_id\": \"5\" } }\n{ \"name\": \"Nike Air Max 270\", \"description\": \"Comfortable and stylish sneakers.\", \"tags\": [\"footwear\", \"sportswear\"] }\nPerform the query_string Query with Boosting:\n\nUse a query_string query to create an OR condition within the query.\nUse a function_score query to boost the score of documents where the tags field contains a specific value (e.g., \"chocolate\").\n\nGET /products/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"query_string\": {\n          \"query\": \"beverage OR bar\"\n        }\n      },\n      \"functions\": [\n        {\n          \"filter\": {\n            \"term\": { \"tags\": \"snack\" }\n          },\n          \"weight\": 2\n        }\n      ],\n      \"boost_mode\": \"multiply\"\n    }\n  }\n}\n\n\n\nTest\n\nRun the above search query.\nRun the following query (which is missing the filter function)\n\nGET /products/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"query\": \"beverage OR bar\"\n    }\n  }\n}\n\nCheck the boosted output to ensure that documents containing \"snack\" in the tags field have a higher score, and that documents are matched based on the OR condition in the query_string.\n\n\n\nConsiderations\n\nThe query_string query allows you to use a query syntax that includes operators such as OR, AND, and NOT to combine different search criteria.\nThe function_score query is used to boost the score of documents based on specific conditions—in this case, whether the tags field contains the value \"snack\".\nThe weight parameter in the function_score query determines the amount by which the score is boosted, and the boost_mode of \"multiply\" multiplies the original score by the boost value.\n\n\n\nClean-up (optional)\n\nDelete the example index\nDELETE products\n\n\n\nDocumentation\n\nQuery String Query\nFunction Score Query\nTerm Query",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  },
  {
    "objectID": "2-searching-data.html#task-write-and-execute-a-search-query-that-is-a-boolean-combination-of-multiple-queries-and-filters",
    "href": "2-searching-data.html#task-write-and-execute-a-search-query-that-is-a-boolean-combination-of-multiple-queries-and-filters",
    "title": "2  Searching Data",
    "section": "2.2 Task: Write and execute a search query that is a Boolean combination of multiple queries and filters",
    "text": "2.2 Task: Write and execute a search query that is a Boolean combination of multiple queries and filters\n\nExample 1: Creating a Boolean search for documents in a book index\n\nRequirements\n\nSearch for documents with a term in the “title”, “description”, and “category” field\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nIndex some documents which will create an index at the same time. The Elastic Console doesn’t like properly formatted documents when calling _bulk so they need to be tightly packed.\nPOST /books/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"title\": \"To Kill a Mockingbird\", \"description\": \"A novel about the serious issues of rape and racial inequality.\", \"category\": \"Fiction\" }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"title\": \"1984\", \"description\": \"A novel that delves into the dangers of totalitarianism.\", \"category\": \"Dystopian\" }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"title\": \"The Great Gatsby\", \"description\": \"A critique of the American Dream.\", \"category\": \"Fiction\" }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"title\": \"Moby Dick\", \"description\": \"The quest of Ahab to exact revenge on the whale Moby Dick.\", \"category\": \"Adventure\" }\n{ \"index\": { \"_id\": \"5\" } }\n{ \"title\": \"Pride and Prejudice\", \"description\": \"A romantic novel that also critiques the British landed gentry at the end of the 18th century.\", \"category\": \"Romance\" }\nCreate a boolean search query. The order in which the various clauses are added don’t matter to the final result.\nGET books/_search\n{\n  \"query\": {\n    \"bool\": {}\n  }\n}\nAdd a must query for the description field. This will return 4 documents.\nGET books/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"terms\": {\n            \"description\": [\n              \"novel\",\n              \"dream\",\n              \"critique\"\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\nAdd a filter query for the category field. This will return 2 documents.\nGET books/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"terms\": {\n            \"description\": [\n              \"novel\",\n              \"dream\",\n              \"critique\"\n            ]\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"term\": {\n            \"category\": \"fiction\"\n          }\n        }\n      ]\n    }\n  }\n}\nAdd a must_not filter for the title field. This will return 1 document.\nGET books/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"terms\": {\n            \"description\": [\n              \"novel\",\n              \"dream\",\n              \"critique\"\n            ]\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"term\": {\n            \"category\": \"fiction\"\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"term\": {\n            \"title\": {\n              \"value\": \"gatsby\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nConsiderations\n\nThe bool query allows for combining multiple queries and filters with Boolean logic.\nThe must, must_not, and filter clauses ensure that all searches and filters must match for a document to be returned.\n\n\n\nTest\n\nVerify that the search query returns documents with the term “novel”, “dream”, and “critique” in the description field. Why are there no documents with the term “critique”?\n\n\n\nClean-up (optional)\n\nDelete the index\nDELETE books\n\n\n\nDocumentation\n\nElasticsearch Boolean Query\nElasticsearch Match Query\nElasticsearch Range Query\nElasticsearch Term Query\n\n\n\n\nExample 2: Creating a Boolean search for finding products within a specific price range and excluding discontinued items\n\nRequirements\n\nFind all documents where the name field exists (name: \\*) and the price field falls within a specified range.\nAdditionally, filter out any documents where the discontinued field is set to true.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nIndex some documents which will create an index at the same time. The Elastic Console doesn’t like properly formatted documents when calling _bulk so they need to be tightly packed.\nPOST /products/_bulk\n{\"index\":{\"_id\":1}}\n{\"name\":\"Coffee Maker\",\"price\":49.99,\"discontinued\":false}\n{\"index\":{\"_id\":2}}\n{\"name\":\"Gaming Laptop\",\"price\":1299.99,\"discontinued\":false}\n{\"index\":{\"_id\":3}}\n{\"name\":\"Wireless Headphones\",\"price\":79.99,\"discontinued\":true}\n{\"index\":{\"_id\":4}}\n{\"name\":\"Smartwatch\",\"price\":249.99,\"discontinued\":false}\nConstruct the first search query (the name field exists and the price field falls within a specified range)\nGET products/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"exists\": {\n            \"field\": \"name\"\n          }\n        },\n        {\n          \"range\": {\n            \"price\": {\n              \"gte\": 70,\n              \"lte\": 500\n            }\n          }\n        }\n      ]\n    }\n  }\n}\nConstruct the second search query (same as above, but check if discontinued is set to true)\nGET products/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"exists\": {\n            \"field\": \"name\"\n          }\n        },\n        {\n          \"range\": {\n            \"price\": {\n              \"gte\": 70,\n              \"lte\": 500\n            }\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"term\": {\n            \"discontinued\": {\n              \"value\": \"true\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nExplanation\n\nSimilar to the previous example, the bool query combines multiple conditions.\nThe must clause specifies documents that must match all conditions within it.\nThe range query ensures the price field is between $70 (inclusive) and $500 (inclusive).\nThe must_not clause excludes documents that match the specified criteria.\nThe term query filters out documents where discontinued is set to true.\n\n\n\nTest\n\nRun the search query and verify the results only include documents for products with:\n\nA price between $70 and $500 (inclusive).\ndiscontinued set to true (not discontinued).\n\n\nThis should return a single document with an ID of 4 (Smartwatch) based on the sample data.\n\n\nConsiderations\n\nThe chosen price range (gte: 70, lte: 500) can be adjusted based on your specific needs.\nYou can modify the match query for name to use more specific criteria if needed.\n\n\n\nClean-up (optional)\n\nDelete the index\nDELETE products\n\n\n\nDocumentation\n\nElasticsearch Boolean Query\nElasticsearch Match Query\nElasticsearch Range Query\nElasticsearch Term Query\n\n\n\n\nExample 3: Creating a Boolean search for e-commerce products\n\nRequirements\n\nSearch for products that belong to the “Electronics” category.\nThe product name should contain the term “phone”.\nExclude products with a price greater than 500.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate an index.\nPUT products\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\" : {\n        \"type\": \"text\"\n      },\n      \"category\" : {\n        \"type\": \"text\"\n      },\n      \"price\" : {\n        \"type\": \"float\"\n      }\n    }\n  }\n}\nIndex some documents which will create an index at the same time. The Elastic Console doesn’t like properly formatted documents when calling _bulk so they need to be tightly packed.\nPOST /products/_bulk\n{\"index\": { \"_id\": 1 } }\n{ \"name\": \"Smartphone X\", \"category\": \"Electronics\", \"price\": 399.99 }\n{\"index\": { \"_id\": 2 } }\n{ \"name\": \"Laptop Y\", \"category\": \"Electronics\", \"price\": 799.99 }\n{\"index\": { \"_id\": 3 } }\n{ \"name\": \"Headphones Z\", \"category\": \"Electronics\", \"price\": 99.99 }\n{\"index\": { \"_id\": 4 } }\n{ \"name\": \"Gaming Console\", \"category\": \"Electronics\", \"price\": 299.99 }\nCreate a term query that only matches the category “electronics”. This returns all 4 documents.\nGET products/_search\n{\n  \"query\": {\n    \"term\": {\n      \"category\": {\n        \"value\": \"electronics\"\n      }\n    }\n  }\n}\nCreate another query using wildcard to return docs that includes “phone”. This returns only 2 documents.\nGET products/_search\n{\n  \"query\": {\n    \"wildcard\": {\n      \"name\": {\n        \"value\": \"*phone*\"\n      }\n    }\n  }\n}\nCreate another query using range that returns docs with any price less than $500. This returns 3 documents.\nGET products/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"lt\": 500\n      }\n    }\n  }\n}\nCombine the above into one bool query with a single must that contains the three queries. This will return the 2 matching documents.\nGET products/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"category\": {\n              \"value\": \"electronics\"\n            }\n          }\n        },\n        {\n          \"wildcard\": {\n            \"name\": {\n              \"value\": \"*phone*\"\n            }\n          }\n        },\n        {\n          \"range\": {\n            \"price\": {\n              \"lt\": 500\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nTest\n\nThe search results should include the following documents:\n\nSmartphone X\nHeadphones Z\n\n\n\n\nConsiderations\n\nThe term query is used for matches on the category field.\nThe wildcard query is used for matches on the name field.\nThe range query is used to filter out documents based on price.\nThe bool.must query combines these conditions using the specified occurrence types.\n\n\n\nClean-up (optional)\n\nDelete the index\nDELETE products\n\n\n\nDocumentation\n\nBoolean Query\nMatch Query\nRange Query\nTerm Query\nWildcard Query\n\n\n\n\nExample 4: Creating a Boolean search for e-commerce products\n\nRequirements\n\nCreate an index named “products”.\nCreate at least 4 documents with varying categories, prices, ratings, and brands.\nCreate a boolean query\n\nUse the must:\n\nreturn just electronics\nproducts more than $500\n\nUse must_not:\n\nrating less than 4\n\nUse filter:\n\nonly Apple products\n\n\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate the “products” index\nPUT products\n{\n  \"mappings\": {\n    \"properties\": {\n      \"brand\": {\n        \"type\": \"text\"\n      },\n      \"category\": {\n        \"type\": \"keyword\"\n      },\n      \"name\": {\n        \"type\": \"text\"\n      },\n      \"price\": {\n        \"type\": \"long\"\n      },\n      \"rating\": {\n        \"type\": \"float\"\n      }\n    }\n  }\n}\nAdd some sample documents using the _bulk endpoint.\nPOST /products/_bulk\n{\"index\":{\"_id\":1}}\n{\"name\":\"Laptop\",\"category\":\"Electronics\",\"price\":1200,\"rating\":4.5,\"brand\":\"Apple\"}\n{\"index\":{\"_id\":2}}\n{\"name\":\"Smartphone\",\"category\":\"Electronics\",\"price\":800,\"rating\":4.2,\"brand\":\"Samsung\"}\n{\"index\":{\"_id\":3}}\n{\"name\":\"Sofa\",\"category\":\"Furniture\",\"price\":1000,\"rating\":3.8,\"brand\":\"IKEA\"}\n{\"index\":{\"_id\":4}}\n{\"name\":\"Headphones\",\"category\":\"Electronics\",\"price\":150,\"rating\":2.5,\"brand\":\"Sony\"}\n{\"index\":{\"_id\":5}}\n{\"name\":\"Dining Table\",\"category\":\"Furniture\",\"price\":600,\"rating\":4.1,\"brand\":\"Ashley\"}\nCreate a term query that only matches the category “electronics”. This returns 3 documents.\nGET products/_search\n{\n  \"query\": {\n    \"term\": {\n      \"category\": {\n        \"value\": \"electronics\"\n      }\n    }\n  }\n}\nCreate a range query to return products whose price is greater than $500. This should return 4 documents (why?).\nGET products/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"gte\": 500\n      }\n    }\n  }\n}\nCreate another range query to return products with a rating less than 4. This will return 2 documents.\nGET products/_search\n{\n  \"query\": {\n    \"range\": {\n      \"rating\": {\n        \"lt\": 4\n      }\n    }\n  }\n}\nCreate another term query to return only Apple branded products. This will return 2 documents.\nGET products/_search\n{\n  \"query\": {\n    \"term\": {\n      \"brand\": {\n        \"value\": \"apple\"\n      }\n    }\n  }\n}\nAssemble the bool query by placing each query in their appropriate must, must_not and filter node.\nGET products/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"category\": {\n              \"value\": \"electronics\"\n            }\n          }\n        },\n        {\n          \"range\": {\n            \"price\": {\n              \"gte\": 500\n            }\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"range\": {\n            \"rating\": {\n              \"lt\": 4\n            }\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"term\": {\n            \"brand\": {\n              \"value\": \"apple\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nTest\n\nCheck the response from the search query to ensure that it returns the expected documents\n\nproducts in the “Electronics” category\na price greater than $500\nexcluding products with a rating less than 4\nfrom the brand “Apple”\n\n\n\n\nConsiderations\n\nThe filter clause is used to include only documents with the brand “Apple”.\n\n\n\nClean-up (optional)\n\nDelete the index\nDELETE products\n\n\n\nDocumentation\n\nElasticsearch Boolean Query\nElasticsearch Term Query\nElasticsearch Range Query",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  },
  {
    "objectID": "2-searching-data.html#task-create-an-asynchronous-search",
    "href": "2-searching-data.html#task-create-an-asynchronous-search",
    "title": "2  Searching Data",
    "section": "2.3 Task: Create an asynchronous search",
    "text": "2.3 Task: Create an asynchronous search\nAsynchronous search uses the same parameters as regular search with a few extra features listed here. For example, in the solution below the documentation for the size option is here. There is only one example here as you can look up the other options as needed during the exam.\n\nExample 1: Executing an asynchronous search on a large log index\n\nRequirements\n\nAn Elasticsearch index named “logs” with a large number of documents (e.g., millions of log entries).\nPerform a search on the “logs” index that may take a long time to complete due to the size of the index.\nRetrieve the search results asynchronously without blocking the client.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nIf you were submitting a normal/synchronous search to an index called logs your request would look something like this:\nPOST /logs/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"size\": 10000\n}\nTo turn your request into an asynchronous search request turn _search to _async_search\nPOST /logs/_async_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"size\": 10000\n}\n\nThis request will return an id and a response object containing partial results if available.\n\nCheck the status of the asynchronous search using the id.\nGET /_async_search/status/{id}\nRetrieve the search results using the id.\nGET /_async_search/{id}\n\n\n\nTest\n\nIndex a large number of sample log documents or use an index with a large number of documents.\nExecute the asynchronous search request and store the returned id.\nPeriodically check the status of the search using the id and the /_async_search/status/{id} endpoint.\nGET /_async_search/status/{id}\nOnce the search is complete, retrieve the final results using the id and the /_async_search/{id} endpoint.\n\nGET /_async_search/{id}\n\n\nConsiderations\n\nThe _async_search endpoint is used to submit an asynchronous search request.\nThe id returned by the initial request is used to check the status and retrieve the final results.\nAsynchronous search is useful for long-running searches on large datasets, as it doesn’t block the client while the search is being processed.\n\n\n\nClean-up (optional)\n\nIf you created an index (for example, logs) for this example you might want to delete it.\nDELETE logs\n\n\n\nDocumentation\n\nAsync Search API\nSubmitting Async Search\nStatus Check Async Search\nRetrieving Async Search Results",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  },
  {
    "objectID": "2-searching-data.html#task-write-and-execute-metric-and-bucket-aggregations",
    "href": "2-searching-data.html#task-write-and-execute-metric-and-bucket-aggregations",
    "title": "2  Searching Data",
    "section": "2.4 Task: Write and execute metric and bucket aggregations",
    "text": "2.4 Task: Write and execute metric and bucket aggregations\n\nExample 1: Creating Metric and Bucket Aggregations for Product Prices\n\nRequirements\n\nCreate an index called product_prices.\nIndex at least four documents using the _bulk endpoint.\nExecute metric and bucket aggregations in a single\n\nbucket the category field\ncalculate the average price per bucket\nfind the maximum price per bucket\nfind the minimum price per bucket\n\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\n\nEnsure you have access to Kibana or any REST client to execute the following requests.\n\nCreate an index with the following schema (needed for the aggregations to work properly).\nPUT product_prices\n{\n  \"mappings\": {\n    \"properties\": {\n      \"product\": {\n        \"type\": \"text\"\n      },\n      \"category\": {\n        \"type\": \"keyword\"\n      },\n      \"price\": {\n        \"type\": \"double\"\n      }\n    }\n  }\n}\nIndex documents.\nPOST /product_prices/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"product\": \"Elasticsearch Guide\", \"category\": \"Books\", \"price\": 29.99 }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"product\": \"Advanced Elasticsearch\", \"category\": \"Books\", \"price\": 39.99 }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"product\": \"Elasticsearch T-shirt\", \"category\": \"Apparel\", \"price\": 19.99 }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"product\": \"Elasticsearch Mug\", \"category\": \"Apparel\", \"price\": 12.99 }\nExecute a simple aggregation (should return 2 buckets).\nGET product_prices/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"category_buckets\": {\n      \"terms\": {\n        \"field\": \"category\"\n      }\n    }\n  }\n}\nAdd and execute a single sub-aggregation to determine the average price per category (bucket).\nGET product_prices/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"category_buckets\": {\n      \"terms\": {\n        \"field\": \"category\"\n      },\n      \"aggs\": {\n        \"avg_price\": {\n          \"avg\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    }\n  }\n}\nAdd min and max sub-aggregations and execute the query.\nGET product_prices/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"category_buckets\": {\n      \"terms\": {\n        \"field\": \"category\"\n      },\n      \"aggs\": {\n        \"avg_price\": {\n          \"avg\": {\n            \"field\": \"price\"\n          }\n        },\n        \"min_price\" : {\n          \"min\": {\n            \"field\": \"price\"\n          }\n        },\n        \"max_price\": {\n          \"max\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\nTest\n\nVerify the index creation.\nGET /product_prices\nVerify the documents have been indexed.\nGET /product_prices/_search\nExecute the aggregation query and verify the results.\n{\n  ...\n  \"aggregations\": {\n    \"category_buckets\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"Apparel\",\n          \"doc_count\": 2,\n          \"avg_price\": {\n            \"value\": 16.49\n          },\n          \"min_price\": {\n            \"value\": 12.99\n          },\n          \"max_price\": {\n            \"value\": 19.99\n          }\n        },\n        {\n          \"key\": \"Books\",\n          \"doc_count\": 2,\n          \"avg_price\": {\n            \"value\": 34.99\n          },\n          \"min_price\": {\n            \"value\": 29.99\n          },\n          \"max_price\": {\n            \"value\": 39.99\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nConsiderations\n\nThe category field must be of type keyword.\nThe terms aggregation creates buckets for each unique category.\nThe avg, min, and max sub-aggregations calculate the average, minimum, and maximum prices within each category bucket.\nSetting size to 0 ensures that only aggregation results are returned, not individual documents.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE product_prices\n\n\n\nDocumentation\n\nAggregations\nTerms Aggregation\nAvg Aggregation\nMax Aggregation\nMin Aggregation\n\n\n\n\nExample 2: Creating Metric and Bucket Aggregations for Website Traffic\n\nRequirements\n\nCreate a new index with four documents representing website traffic data.\nAggregate the following:\n\nGroup traffic by country.\nCalculate the total page views.\nCalculate the average page views per country.\n\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate a new index.\nPUT traffic\n{\n  \"mappings\": {\n    \"properties\": {\n      \"country\": {\n        \"type\": \"keyword\"\n      },\n      \"page_views\": {\n        \"type\": \"long\"\n      }\n    }\n  }\n}\nAdd four documents representing website traffic data.\nPOST /traffic/_bulk\n{\"index\":{}}\n{\"country\":\"USA\",\"page_views\":100}\n{\"index\":{}}\n{\"country\":\"USA\",\"page_views\":200}\n{\"index\":{}}\n{\"country\":\"Canada\",\"page_views\":50}\n{\"index\":{}}\n{\"country\":\"Canada\",\"page_views\":75}\nExecute the bucket aggregation for country (should return 2 buckets).\nGET traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"country_bucket\": {\n      \"terms\": {\n        \"field\": \"country\"\n      }\n    }\n  }\n}\nAdd the sum aggregation for total page_views (should return 1 aggregation).\nGET traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"country_bucket\": {\n      \"terms\": {\n        \"field\": \"country\"\n      }\n    },\n    \"total_page_views\": {\n      \"sum\": {\n        \"field\": \"page_views\"\n      }\n    }\n  }\n}\nAdd a sub-aggregation for average page_views per country (should appear in 2 buckets).\nGET traffic/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"country_bucket\": {\n      \"terms\": {\n        \"field\": \"country\"\n      },\n      \"aggs\": {\n        \"avg_page_views\": {\n          \"avg\": {\n            \"field\": \"page_views\"\n          }\n        }\n      }\n    },\n    \"total_page_views\": {\n      \"sum\": {\n        \"field\": \"page_views\"\n      }\n    }\n  }\n}\n\n\n\nTest\n\nVerify the index creation.\nGET /traffic\nVerify the documents have been indexed.\nGET /traffic/_search\nVerify that the total page views are calculated correctly (should be 425).\nGET /traffic/_search\n{\n  \"aggs\": {\n    \"total_page_views\": {\n      \"sum\": {\n        \"field\": \"page_views\"\n      }\n    }\n  }\n}\nVerify that the traffic is grouped correctly by country and average page views are calculated.\nGET /traffic/_search\n{\n  \"aggs\": {\n    \"traffic_by_country\": {\n      \"terms\": {\n        \"field\": \"country\"\n      },\n      \"aggs\": {\n        \"avg_page_views\": {\n          \"avg\": {\n            \"field\": \"page_views\"\n          }\n        }\n      }\n    }\n  }\n}\nResponse:\n{\n  ...\n  \"aggregations\": {\n    \"country_bucket\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"Canada\",\n          \"doc_count\": 2,\n          \"avg_page_views\": {\n            \"value\": 62.5\n          }\n        },\n        {\n          \"key\": \"USA\",\n          \"doc_count\": 2,\n          \"avg_page_views\": {\n            \"value\": 150\n          }\n        }\n      ]\n    },\n    \"total_page_views\": {\n      \"value\": 425\n    }\n  }\n}\n\n\n\nConsiderations\n\nThe country field must be of type keyword.\nThe terms bucket aggregation is used to group traffic by country.\nThe sum metric aggregation is used to calculate the total page views.\nThe avg metric aggregation is used to calculate the average page views per country.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE traffic\n\n\n\nDocumentation\n\nAggregations\nMetric Aggregations\nBucket Aggregations\nTerms Aggregation\n\n\n\n\nExample 3: Creating Metric and Bucket Aggregations for Analyzing Employee Salaries\n\nRequirements\n\nAn Elasticsearch index named employees with documents containing fields name, department, position, salary, hire_date.\nCalculate the average salary across all employees.\nGroup the employees by department\nCalculate the maximum salary for each department.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate an index with the proper mapping for the department as we want to bucket by it.\nPUT employees\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\"\n      },\n      \"department\": {\n        \"type\": \"keyword\"\n      },\n      \"position\": {\n        \"type\": \"text\"\n      },\n      \"salary\": {\n        \"type\": \"integer\"\n      },\n      \"hire_date\": {\n        \"type\": \"date\"\n      }\n    }\n  }\n}\nIndex sample employee documents using the /_bulk endpoint.\nPOST /employees/_bulk\n{\"index\":{\"_id\":1}}\n{\"name\":\"John Doe\", \"department\":\"Engineering\", \"position\":\"Software Engineer\", \"salary\":80000, \"hire_date\":\"2018-01-15\"}\n{\"index\":{\"_id\":2}}\n{\"name\":\"Jane Smith\", \"department\":\"Engineering\", \"position\":\"DevOps Engineer\", \"salary\":75000, \"hire_date\":\"2020-03-01\"}\n{\"index\":{\"_id\":3}}\n{\"name\":\"Bob Johnson\", \"department\":\"Sales\", \"position\":\"Sales Manager\", \"salary\":90000, \"hire_date\":\"2016-06-01\"}\n{\"index\":{\"_id\":4}}\n{\"name\":\"Alice Williams\", \"department\":\"Sales\", \"position\":\"Sales Representative\", \"salary\":65000, \"hire_date\":\"2019-09-15\"}\nCalculate the average salary of all employees\nGET employees/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"avg_salary_all_emps\": {\n      \"avg\": {\n        \"field\": \"salary\"\n      }\n    }\n  }\n}\nAdd grouping the employees by department\nGET employees/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"avg_salary_all_emps\": {\n      \"avg\": {\n        \"field\": \"salary\"\n      }\n    },\n    \"employees_by_department\" : {\n      \"terms\": {\n        \"field\": \"department\"\n      }\n    }\n  }\n}\nAdd calculating the highest salary of all employees by department\nGET employees/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"avg_salary_all_emps\": {\n      \"avg\": {\n        \"field\": \"salary\"\n      }\n    },\n    \"employees_by_department\": {\n      \"terms\": {\n        \"field\": \"department\"\n      },\n      \"aggs\": {\n        \"max_salary_by_department\": {\n          \"max\": {\n            \"field\": \"salary\"\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\nTest\n\nVerify the index creation.\nGET /employees\nVerify the documents have been indexed.\nGET /employees/_search\nExecute the aggregation query, and it should return the following:\n{\n  ...\n  \"aggregations\": {\n    \"avg_salary_all_emps\": {\n      \"value\": 77500\n    },\n    \"employees_by_department\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"Engineering\",\n          \"doc_count\": 2,\n          \"max_salary_by_department\": {\n            \"value\": 80000\n          }\n        },\n        {\n          \"key\": \"Sales\",\n          \"doc_count\": 2,\n          \"max_salary_by_department\": {\n            \"value\": 90000\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nConsiderations\n\nThe department field must be of type keyword.\nThe size parameter is set to 0 to exclude hit documents from the response.\nThe avg_salary_all_emps metric aggregation calculates the average of the salary field across all documents.\nThe employees_by_department bucket aggregation groups the documents by the department field.\nThe max_salary_by_department sub-aggregation calculates the maximum value of the salary field for each department.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE employees\n\n\n\nDocumentation\n\nElasticsearch Aggregations\nMetric Aggregations\nBucket Aggregations\nTerms Aggregation",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  },
  {
    "objectID": "2-searching-data.html#task-write-and-execute-aggregations-that-contain-subaggregations",
    "href": "2-searching-data.html#task-write-and-execute-aggregations-that-contain-subaggregations",
    "title": "2  Searching Data",
    "section": "2.5 Task: Write and execute aggregations that contain subaggregations",
    "text": "2.5 Task: Write and execute aggregations that contain subaggregations\n\nExample 1: Creating aggregations and sub-aggregations for Product Categories and Prices\n\nRequirements\n\nCreate aggregations\n\nby category\nsub-aggregation of average price by category\n\nprice ranges: $0 to $20, $20-$40, $40 and up\n\n\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate an index.\nPUT /product_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"product\": {\n        \"type\": \"text\"\n      },\n      \"category\": {\n        \"type\": \"keyword\"\n      },\n      \"price\": {\n        \"type\": \"double\"\n      }\n    }\n  }\n}\nIndex some sample documents.\nPOST /product_index/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"product\": \"Elasticsearch Guide\", \"category\": \"Books\", \"price\": 29.99 }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"product\": \"Advanced Elasticsearch\", \"category\": \"Books\", \"price\": 39.99 }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"product\": \"Elasticsearch T-shirt\", \"category\": \"Apparel\", \"price\": 19.99 }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"product\": \"Elasticsearch Mug\", \"category\": \"Apparel\", \"price\": 12.99 }\nCreate an aggregation by category.\nGET product_index/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"category_buckets\": {\n      \"terms\": {\n        \"field\": \"category\"\n      }\n    }\n  }\n}\nCreate a sub-aggregations of average price.\nGET product_index/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"category_buckets\": {\n      \"terms\": {\n        \"field\": \"category\"\n      },\n      \"aggs\": {\n        \"average_price\": {\n          \"avg\": {\n            \"field\": \"price\"\n          }\n        }\n      }\n    }\n  }\n}\nCreate a sub-aggregations of price ranges ($0-$20, $10-$40, $40 and up).\nGET product_index/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"category_buckets\": {\n      \"terms\": {\n        \"field\": \"category\"\n      },\n      \"aggs\": {\n        \"average_price\": {\n          \"avg\": {\n            \"field\": \"price\"\n          }\n        },\n        \"price_ranges\" : {\n          \"range\": {\n            \"field\": \"price\",\n            \"ranges\": [\n              {\n                \"to\": 20\n              },\n              {\n                \"from\": 20,\n                \"to\": 40\n              },\n              {\n                \"from\": 40\n              }\n            ]\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\nTest\n\nVerify the index creation and mappings.\nGET /product_index\nVerify the test documents are in the index.\nGET /product_index/_search\nExecute the aggregation query and confirm the results.\n{\n  ...\n  \"aggregations\": {\n    \"category_buckets\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"Apparel\",\n          \"doc_count\": 2,\n          \"average_price\": {\n            \"value\": 16.49\n          },\n          \"price_ranges\": {\n            \"buckets\": [\n              {\n                \"key\": \"*-20.0\",\n                \"to\": 20,\n                \"doc_count\": 2\n              },\n              {\n                \"key\": \"20.0-40.0\",\n                \"from\": 20,\n                \"to\": 40,\n                \"doc_count\": 0\n              },\n              {\n                \"key\": \"40.0-*\",\n                \"from\": 40,\n                \"doc_count\": 0\n              }\n            ]\n          }\n        },\n        {\n          \"key\": \"Books\",\n          \"doc_count\": 2,\n          \"average_price\": {\n            \"value\": 34.99\n          },\n          \"price_ranges\": {\n            \"buckets\": [\n              {\n                \"key\": \"*-20.0\",\n                \"to\": 20,\n                \"doc_count\": 0\n              },\n              {\n                \"key\": \"20.0-40.0\",\n                \"from\": 20,\n                \"to\": 40,\n                \"doc_count\": 2\n              },\n              {\n                \"key\": \"40.0-*\",\n                \"from\": 40,\n                \"doc_count\": 0\n              }\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nConsiderations\n\nSetting size: 0 ensures the search doesn’t return any documents, focusing solely on the aggregations.\nThe category field must be of type keyword.\nThe terms aggregation creates buckets for each unique category.\nThe avg sub-aggregation calculates the average price within each category bucket.\nThe range sub-aggregation divides the prices into specified ranges within each category bucket.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE product_index\n\n\n\nDocumentation\n\nAggregations\nAvg Aggregation\nRange Aggregation\nTerms Aggregation\n\n\n\n\nExample 2: Creating aggregations and sub-aggregations for Employee Data Analysis\n\nRequirements\n\nUse the terms aggregation to group employees by department.\nUse the avg sub-aggregation to calculate the average salary per department.\nUse the filters sub-aggregation to group employees by job_title.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate a new index called employees.\nPUT employees\n{\n  \"mappings\": {\n    \"properties\": {\n      \"department\": {\n        \"type\": \"keyword\"\n      },\n      \"salary\": {\n        \"type\": \"integer\"\n      },\n      \"job_title\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\nInsert four documents representing employee data.\nPOST /employees/_bulk\n{\"index\":{}}\n{\"department\":\"Sales\",\"salary\":100000,\"job_title\":\"Manager\"}\n{\"index\":{}}\n{\"department\":\"Sales\",\"salary\":80000,\"job_title\":\"Representative\"}\n{\"index\":{}}\n{\"department\":\"Marketing\",\"salary\":120000,\"job_title\":\"Manager\"}\n{\"index\":{}}\n{\"department\":\"Marketing\",\"salary\":90000,\"job_title\":\"Coordinator\"}\nExecute an aggregation by department.\nGET employees/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"employees_by_department\": {\n      \"terms\": {\n        \"field\": \"department\"\n      }\n    }\n  }\n}\nAdd the sub-aggregations for average salary by department.\nGET employees/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"employees_by_department\": {\n      \"terms\": {\n        \"field\": \"department\"\n      },\n      \"aggs\": {\n        \"avg_salary_by_department\": {\n          \"avg\": {\n            \"field\": \"salary\"\n          }\n        }\n      }\n    }\n  }\n}\nAdd a filters sub-aggregation for each job_title.\nGET employees/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"employees_by_department\": {\n      \"terms\": {\n        \"field\": \"department\"\n      },\n      \"aggs\": {\n        \"avg_salary_by_department\": {\n          \"avg\": {\n            \"field\": \"salary\"\n          }\n        },\n        \"employees_by_title\": {\n          \"filters\": {\n            \"filters\": {\n              \"Managers\": {\n                \"term\": {\n                  \"job_title\": \"Manager\"\n                }\n              },\n              \"Representative\" : {\n                \"term\": {\n                  \"job_title\": \"Representative\"\n                }\n              },\n              \"Coordinator\" : {\n                \"term\": {\n                  \"job_title\": \"Coordinator\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\nTest\n\nVerify the index creation and mappings.\nGET /employees\nVerify the test documents are in the index.\nGET /employees/_search\nVerify that the employees are grouped correctly by department and job title and that the average salary is calculated correctly for each department.\n{\n  ...\n  \"aggregations\": {\n    \"employees_by_department\": {\n      \"doc_count_error_upper_bound\": 0,\n      \"sum_other_doc_count\": 0,\n      \"buckets\": [\n        {\n          \"key\": \"Marketing\",\n          \"doc_count\": 2,\n          \"avg_salary_by_department\": {\n            \"value\": 105000\n          },\n          \"employees_by_title\": {\n            \"buckets\": {\n              \"Coordinator\": {\n                \"doc_count\": 1\n              },\n              \"Managers\": {\n                \"doc_count\": 1\n              },\n              \"Representative\": {\n                \"doc_count\": 0\n              }\n            }\n          }\n        },\n        {\n          \"key\": \"Sales\",\n          \"doc_count\": 2,\n          \"avg_salary_by_department\": {\n            \"value\": 90000\n          },\n          \"employees_by_title\": {\n            \"buckets\": {\n              \"Coordinator\": {\n                \"doc_count\": 0\n              },\n              \"Managers\": {\n                \"doc_count\": 1\n              },\n              \"Representative\": {\n                \"doc_count\": 1\n              }\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nConsiderations\n\nThe department field must be of type keyword.\nSetting size to 0 ensures the search doesn’t return any documents, focusing solely on the aggregations.\nThe terms aggregation is used to group employees by department.\nThe avg sub-aggregation is used to calculate the average salary per department.\nThe filters sub-aggregation is used to group employees by job_title.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE employees\n\n\n\nDocumentation\n\nAggregations\nAvg Aggregation\nFilters Aggregation\nRange Aggregation\nTerms Aggregation\n\n\n\n\nExample 3: Creating aggregations and sub-aggregations for application logs by Hour and Log Level\n\nRequirements\n\nAnalyze application logs stored in an Elasticsearch index named app-logs.\nUse a date_histogram aggregation to group logs by the hour.\nWithin each hour bucket, create a sub-aggregation to group logs by their severity level (log_level).\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate a new index called app-logs.\nPUT app-logs\n{\n  \"mappings\": {\n    \"properties\": {\n      \"@timestamp\": {\n        \"type\": \"date\"\n      },\n      \"log_level\": {\n        \"type\": \"keyword\"\n      },\n      \"message\": {\n        \"type\": \"text\"\n      }\n    }\n  }\n}\nInsert sample data.\nPOST /app-logs/_bulk\n{\"index\":{},\"_id\":\"1\"}\n{\"@timestamp\":\"2024-05-24T10:30:00\",\"log_level\":\"INFO\",\"message\":\"Application started successfully.\"}\n{\"index\":{},\"_id\":\"2\"}\n{\"@timestamp\":\"2024-05-24T11:15:00\",\"log_level\":\"WARNING\",\"message\":\"Potential memory leak detected.\"}\n{\"index\":{},\"_id\":\"3\"}\n{\"@timestamp\":\"2024-05-24T12:00:00\",\"log_level\":\"ERROR\",\"message\":\"Database connection failed.\"}\n{\"index\":{},\"_id\":\"4\"}\n{\"@timestamp\":\"2024-05-24T10:45:00\",\"log_level\":\"DEBUG\",\"message\":\"Processing user request.\"}\nUse a date_histogram aggregation to group logs by the hour.\nGET app-logs/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"logs_by_the_hour\": {\n      \"date_histogram\": {\n        \"field\": \"@timestamp\",\n        \"fixed_interval\": \"1h\"\n      }\n    }\n  }\n}\nWithin each hour bucket, create a sub-aggregation to group logs by their severity level (log_level).\nGET app-logs/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"logs_by_the_hour\": {\n      \"date_histogram\": {\n        \"field\": \"@timestamp\",\n        \"fixed_interval\": \"1h\"\n      },\n      \"aggs\": {\n        \"log_severity\": {\n          \"terms\": {\n            \"field\": \"log_level\"\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\nTest\n\nVerify the index creation and mappings.\nGET /app-logs\nVerify the test documents are in the index.\nGET /app-logs/_search\nRun the search query and examine the response.\n{\n  ...\n  \"aggregations\": {\n    \"logs_by_the_hour\": {\n      \"buckets\": [\n        {\n          \"key_as_string\": \"2024-05-24T10:00:00.000Z\",\n          \"key\": 1716544800000,\n          \"doc_count\": 2,\n          \"log_severity\": {\n            \"doc_count_error_upper_bound\": 0,\n            \"sum_other_doc_count\": 0,\n            \"buckets\": [\n              {\n                \"key\": \"DEBUG\",\n                \"doc_count\": 1\n              },\n              {\n                \"key\": \"INFO\",\n                \"doc_count\": 1\n              }\n            ]\n          }\n        },\n        {\n          \"key_as_string\": \"2024-05-24T11:00:00.000Z\",\n          \"key\": 1716548400000,\n          \"doc_count\": 1,\n          \"log_severity\": {\n            \"doc_count_error_upper_bound\": 0,\n            \"sum_other_doc_count\": 0,\n            \"buckets\": [\n              {\n                \"key\": \"WARNING\",\n                \"doc_count\": 1\n              }\n            ]\n          }\n        },\n        {\n          \"key_as_string\": \"2024-05-24T12:00:00.000Z\",\n          \"key\": 1716552000000,\n          \"doc_count\": 1,\n          \"log_severity\": {\n            \"doc_count_error_upper_bound\": 0,\n            \"sum_other_doc_count\": 0,\n            \"buckets\": [\n              {\n                \"key\": \"ERROR\",\n                \"doc_count\": 1\n              }\n            ]\n          }\n        }\n      ]\n    }\n  }\n}\n\n\n\nConsiderations\n\nSetting size to 0 ensures the search doesn’t return any documents, focusing solely on the aggregations.\nThe date_histogram aggregation groups documents based on the @timestamp field with an interval of one hour.\nThe nested terms aggregation within the logs_by_hour aggregation counts the occurrences of each unique log_level within each hour bucket.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE app-logs\n\n\n\nDocumentation\n\nBucket Aggregations\nDate Histogram Aggregation\nTerms Aggregation\n\n\n\n\nExample 4: Finding the Stock with the Highest Daily Volume of the Month\nThis is taken from a webinar by Elastic to show a sample question and answer to the Certified Engineer Exam. Their answer was wrong and didn’t need aggregations.\n\nRequirements\n\nCreate a query to find the stock with the highest daily volume for the current month.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nIndex sample data:\n\nUse the _bulk endpoint to index sample stock data.\nEnsure the data includes fields for stock_name, date, and volume.\nPOST _bulk\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"1\" } }\n{ \"stock_name\": \"AAPL\", \"date\": \"2024-07-01\", \"volume\": 1000000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"2\" } }\n{ \"stock_name\": \"AAPL\", \"date\": \"2024-07-02\", \"volume\": 1500000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"3\" } }\n{ \"stock_name\": \"GOOGL\", \"date\": \"2024-07-01\", \"volume\": 2000000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"4\" } }\n{ \"stock_name\": \"GOOGL\", \"date\": \"2024-07-02\", \"volume\": 2500000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"5\" } }\n{ \"stock_name\": \"MSFT\", \"date\": \"2024-07-01\", \"volume\": 3000000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"6\" } }\n{ \"stock_name\": \"MSFT\", \"date\": \"2024-07-02\", \"volume\": 3500000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"7\" } }\n{ \"stock_name\": \"TSLA\", \"date\": \"2024-07-01\", \"volume\": 4000000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"8\" } }\n{ \"stock_name\": \"TSLA\", \"date\": \"2024-07-02\", \"volume\": 4500000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"9\" } }\n{ \"stock_name\": \"AMZN\", \"date\": \"2024-07-01\", \"volume\": 5000000 }\n{ \"index\": { \"_index\": \"stocks\", \"_id\": \"10\" } }\n{ \"stock_name\": \"AMZN\", \"date\": \"2024-07-02\", \"volume\": 5500000 }\n\nCreate the query. The stocks in the index are all from July, but you want just the stocks for the latest month. Update the above dates so the query will work for you.\n  GET stocks/_search\n  {\n    \"size\": 1, \n    \"query\": {\n      \"range\": {\n        \"date\": {\n          \"gte\": \"now/M\",\n          \"lte\": \"now\"\n        }\n      }\n    }\n  }\nThe results of the query should be all the stocks from a given month. Now sort those stocks by their volume and display the top pick.\nGET stocks/_search\n{\n  \"size\": 1, \n  \"query\": {\n    \"range\": {\n      \"date\": {\n        \"gte\": \"now/M\",\n        \"lte\": \"now\"\n      }\n    }\n  },\n  \"sort\": [\n    {\n      \"volume\": {\n        \"order\": \"desc\"\n      }\n    }\n  ]\n}\n\n\n\nTest\n\nVerify the index creation and mappings.\nGET /stocks\nVerify the test documents are in the index.\nGET /stocks/_search\nRun the query and confirm that the stock with the highest daily volume of the month is displayed.\n{\n  ...\n    \"hits\": [\n      {\n        \"_index\": \"stocks\",\n        \"_id\": \"10\",\n        \"_score\": null,\n        \"_source\": {\n          \"stock_name\": \"AMZN\",\n          \"date\": \"2024-07-02\",\n          \"volume\": 5500000\n        },\n        \"sort\": [\n          5500000\n        ]\n      }\n    ]\n  }\n}\n\n\n\nConsiderations\n\nThe range clause returned the stocks for the current month\nThe sort clause brought the highest volume of any stock to the top and size of 1 displayed that one record\n\n\n\nClean-up (Optional)\n\nDelete the stocks index to clean up the data:\nDELETE /stocks\n\n\n\nDocumentation\n\nElasticsearch Bulk API\nElasticsearch Date Histogram Aggregation\nElasticsearch Max Aggregation\nElasticsearch Top Hits Aggregation\n\n\n\n\nExample 5: Aggregating Sales Data by Month with Sub-Aggregation of Total Sales Value\n\nRequirements\n\nAggregate e-commerce sales data by month, creating at least 12 date buckets.\nPerform a sub-aggregation to calculate the total sales value within each month.\n\n\n\nSteps\n\nIndex Sample Sales Documents Using _bulk Endpoint:\nPOST /sales_data/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"order_date\": \"2023-01-15\", \"product\": \"Yoo-hoo Beverage\", \"quantity\": 10, \"price\": 1.99 }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"order_date\": \"2023-02-20\", \"product\": \"Apple iPhone 12\", \"quantity\": 1, \"price\": 799.99 }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"order_date\": \"2023-03-05\", \"product\": \"Choco-Lite Bar\", \"quantity\": 25, \"price\": 0.99 }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"order_date\": \"2023-04-10\", \"product\": \"Nike Air Max 270\", \"quantity\": 3, \"price\": 150.00 }\n{ \"index\": { \"_id\": \"5\" } }\n{ \"order_date\": \"2023-05-18\", \"product\": \"Samsung Galaxy S21\", \"quantity\": 2, \"price\": 699.99 }\n{ \"index\": { \"_id\": \"6\" } }\n{ \"order_date\": \"2023-06-22\", \"product\": \"Yoo-hoo Beverage\", \"quantity\": 15, \"price\": 1.99 }\n{ \"index\": { \"_id\": \"7\" } }\n{ \"order_date\": \"2023-07-03\", \"product\": \"Choco-Lite Bar\", \"quantity\": 30, \"price\": 0.99 }\n{ \"index\": { \"_id\": \"8\" } }\n{ \"order_date\": \"2023-08-25\", \"product\": \"Apple iPhone 12\", \"quantity\": 1, \"price\": 799.99 }\n{ \"index\": { \"_id\": \"9\" } }\n{ \"order_date\": \"2023-09-10\", \"product\": \"Nike Air Max 270\", \"quantity\": 4, \"price\": 150.00 }\n{ \"index\": { \"_id\": \"10\" } }\n{ \"order_date\": \"2023-10-15\", \"product\": \"Samsung Galaxy S21\", \"quantity\": 1, \"price\": 699.99 }\n{ \"index\": { \"_id\": \"11\" } }\n{ \"order_date\": \"2023-11-20\", \"product\": \"Yoo-hoo Beverage\", \"quantity\": 20, \"price\": 1.99 }\n{ \"index\": { \"_id\": \"12\" } }\n{ \"order_date\": \"2023-12-30\", \"product\": \"Choco-Lite Bar\", \"quantity\": 50, \"price\": 0.99 }\nBucket the order_date using a Date Histogram Aggregation with Sub-Aggregation:\n\nUse a date_histogram to create monthly buckets and a sum sub-aggregation to calculate total sales within each month.\nGET /sales_data/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"sales_over_time\": {\n      \"date_histogram\": {\n        \"field\": \"order_date\",\n        \"calendar_interval\": \"month\",\n        \"format\": \"yyyy-MM\"\n      },\n      \"aggs\": {\n        \"total_sales\": {\n          \"sum\": {\n            \"field\": \"total_value\"\n          }\n        }\n      }\n    }\n  }\n}\n\nCalculate the Total Value:\n\nBefore running the above aggregation, ensure that each document includes a total_value field. You could either compute it on the client side or dynamically compute it using an ingest pipeline or a script during the aggregation process.\nFor simplicity, let’s assume the total_value is calculated as quantity * price:\nPOST /sales_data/_update_by_query\n{\n  \"script\": {\n    \"source\": \"ctx._source.total_value = ctx._source.quantity * ctx._source.price\"\n  },\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n\n\n\n\nTest\n\nRun the above GET /sales_data/_search query.\nCheck the output to see 12 date buckets, one for each month, with the total_sales value for each bucket.\n\n\n\nConsiderations\n\nThe date_histogram aggregation is ideal for grouping records by time intervals such as months, weeks, or days.\nThe sum sub-aggregation allows you to calculate the total value of sales within each date bucket.\nEnsure that the total_value field is correctly calculated, as this impacts the accuracy of the sub-aggregation.\n\n\n\nClean-up (Optional)\n\nDelete the stocks index to clean up the data:\nDELETE /sales_data\n\n\n\nDocumentation\n\nDate Histogram Aggregation\nSum Aggregation\nUpdate By Query API\nBulk API",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  },
  {
    "objectID": "2-searching-data.html#task-write-and-execute-a-query-that-searches-across-multiple-clusters",
    "href": "2-searching-data.html#task-write-and-execute-a-query-that-searches-across-multiple-clusters",
    "title": "2  Searching Data",
    "section": "2.6 Task: Write and execute a query that searches across multiple clusters",
    "text": "2.6 Task: Write and execute a query that searches across multiple clusters\nIf you are running your instance of Elasticsearch locally, and need to create an additional cluster so that you can run these examples, go to the Appendix: Adding a Cluster to your Elasticsearch Instance for information on how to set up an additional single-node cluster.\n\nExample 1: Creating search queries for Products in Multiple Clusters\n\nRequirements\n\nSet up two single-node clusters on localhost or Elastic Cloud.\nCreate an index in each cluster.\nIndex at least four documents in each cluster using the _bulk endpoint.\nConfigure cross-cluster search.\nExecute a cross-cluster search query.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nSet up multiple clusters on localhost.\n\n\nAssume you have two clusters, es01 and es02 and they have been set up as directed in the Appendix.\nIn the local cluster, configure communication between the clusters by updating the local cluster settings.\nPUT /_cluster/settings\n{\n  \"persistent\": {\n    \"cluster\": {\n      \"remote\": {\n        \"es01\": {\n          \"seeds\": [\n            \"es01:9300\"\n          ],\n          \"skip_unavailable\": true\n        },\n        \"es02\": {\n          \"seeds\": [\n            \"es02:9300\"\n          ],\n          \"skip_unavailable\": false\n        }\n      }\n    }\n  }\n}\n\n\nCreate a product index in each cluster.\n\n\nFrom the Kibana Console (es01)\nPUT /products\n{\n  \"mappings\": {\n    \"properties\": {\n      \"product\": {\n        \"type\": \"text\"\n      },\n      \"category\": {\n        \"type\": \"keyword\"\n      },\n      \"price\": {\n        \"type\": \"double\"\n      }\n    }\n  }\n}\nFrom the command line (es02).\ncurl -u elastic:[your password here] -X PUT \"http://localhost:9201/products?pretty\" -H 'Content-Type: application/json' -d'\n{\n  \"mappings\": {\n    \"properties\": {\n      \"product\": {\n        \"type\": \"text\"\n      },\n      \"category\": {\n        \"type\": \"keyword\"\n      },\n      \"price\": {\n        \"type\": \"double\"\n      }\n    }\n  }\n}'\n\n\nIndex product documents into each cluster.\n\n\nFor es01:\nPOST /products/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"product\": \"Elasticsearch Guide\", \"category\": \"Books\", \"price\": 29.99 }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"product\": \"Advanced Elasticsearch\", \"category\": \"Books\", \"price\": 39.99 }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"product\": \"Elasticsearch T-shirt\", \"category\": \"Apparel\", \"price\": 19.99 }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"product\": \"Elasticsearch Mug\", \"category\": \"Apparel\", \"price\": 12.99 }\nFor es02 through the command line (note that the final single quote is on a line by itself):\ncurl -u elastic:[your password here] -X POST \"http://localhost:9201/products/_bulk?pretty\" -H 'Content-Type: application/json' -d'\n{ \"index\": { \"_id\": \"5\" } }\n{ \"product\": \"Elasticsearch Stickers\", \"category\": \"Accessories\", \"price\": 4.99 }\n{ \"index\": { \"_id\": \"6\" } }\n{ \"product\": \"Elasticsearch Notebook\", \"category\": \"Stationery\", \"price\": 7.99 }\n{ \"index\": { \"_id\": \"7\" } }\n{ \"product\": \"Elasticsearch Pen\", \"category\": \"Stationery\", \"price\": 3.49 }\n{ \"index\": { \"_id\": \"8\" } }\n{ \"product\": \"Elasticsearch Hoodie\", \"category\": \"Apparel\", \"price\": 45.99 }\n'\n\n\nConfigure Cross-Cluster Search (CCS).\n\n\nIn the local cluster, ensure the remote cluster is configured by checking the settings:\nGET /_cluster/settings?include_defaults=true&filter_path=defaults.cluster.remote\n\n\nExecute a Cross-Cluster Search query.\nGET /products,es02:products/_search\n{\n  \"query\": {\n    \"match\": {\n      \"product\": \"Elasticsearch\"\n    }\n  }\n}\n\n\n\nTest\n\nVerify the index creation.\nGET /products\nFrom the command line execute:\ncurl -u elastic:[your password here] -X GET \"http://localhost:9201/products?pretty\"\nVerify that the documents have been indexed.\nGET /products/_search\nGET /es02:products/_search\nEnsure the remote cluster is correctly configured and visible from the local cluster.\nGET /_remote/info\nExecute a Cross-Cluster Search query.\nGET /products,es02:products/_search\n{\n  \"query\": {\n    \"match\": {\n      \"product\": \"Elasticsearch\"\n    }\n  }\n}\n\n\n\nConsiderations\n\nCross-cluster search is useful for querying data across multiple Elasticsearch clusters, providing a unified search experience.\nEnsure the remote cluster settings are correctly configured in the cluster settings.\nProperly handle the index names to avoid conflicts and ensure clear distinction between clusters.\n\n\n\nClean-up (optional)\n\nDelete the es01 index.\nDELETE products\nDelete the es02 index from the command line.\ncurl -u elastic:[your password here] -X DELETE \"http://localhost:9201/products?pretty\"\n\n\n\nDocumentation\n\nBulk API\nCross-Cluster Search\nCreate Index API\nIndex Document API",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  },
  {
    "objectID": "2-searching-data.html#task-write-and-execute-a-search-that-utilizes-a-runtime-field",
    "href": "2-searching-data.html#task-write-and-execute-a-search-that-utilizes-a-runtime-field",
    "title": "2  Searching Data",
    "section": "2.7 Task: Write and execute a search that utilizes a runtime field",
    "text": "2.7 Task: Write and execute a search that utilizes a runtime field\n\nExample 1: Creating search queries for products with a runtime field for discounted prices\n\nRequirements\n\nCreate an index.\nIndex four documents.\nDefine a runtime field.\nExecute a search query that creates a query-time runtime field with a 10% discount\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate an index.\n\nPUT /product_index\n{\n  \"mappings\": {\n    \"properties\": {\n      \"product\": {\n        \"type\": \"text\"\n      },\n      \"price\": {\n        \"type\": \"double\"\n      },\n      \"category\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\n\nIndex some documents.\n\nPOST /product_index/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"product\": \"Elasticsearch Guide\", \"price\": 29.99, \"category\": \"Books\" }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"product\": \"Advanced Elasticsearch\", \"price\": 39.99, \"category\": \"Books\" }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"product\": \"Elasticsearch T-shirt\", \"price\": 19.99, \"category\": \"Apparel\" }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"product\": \"Elasticsearch Mug\", \"price\": 12.99, \"category\": \"Apparel\" }\n\nDefine a query-time runtime field to return a discounted price.\nGET product_index/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"fields\": [\n    \"product\", \"price\", \"discounted_price\"\n  ], \n  \"runtime_mappings\": {\n    \"discounted_price\": {\n      \"type\": \"double\",\n      \"script\": {\n        \"source\": \"emit(doc['price'].value * 0.9)\"\n      }\n    }\n  }\n}\n\n\n\nTest\n\nVerify the creation of the index and its mappings.\nGET /product_index\nVerify the indexed documents.\nGET /product_index/_search\nExecute the query and confirm the discounted_price.\n{\n  ...\n    \"hits\": [\n      {\n        ...\n        \"fields\": {\n          \"product\": [\n            \"Elasticsearch Guide\"\n          ],\n          \"price\": [\n            29.99\n          ],\n          \"discounted_price\": [\n            26.991\n          ]\n        }\n      },\n      {\n        ...\n        \"fields\": {\n          \"product\": [\n            \"Advanced Elasticsearch\"\n          ],\n          \"price\": [\n            39.99\n          ],\n          \"discounted_price\": [\n            35.991\n          ]\n        }\n      },\n      {\n        ...\n        \"fields\": {\n          \"product\": [\n            \"Elasticsearch T-shirt\"\n          ],\n          \"price\": [\n            19.99\n          ],\n          \"discounted_price\": [\n            17.991\n          ]\n        }\n      },\n      {\n        ...\n        \"fields\": {\n          \"product\": [\n            \"Elasticsearch Mug\"\n          ],\n          \"price\": [\n            12.99\n          ],\n          \"discounted_price\": [\n            11.691\n          ]\n        }\n      }\n    ]\n  }\n}\n\n\n\nConsiderations\n\nRuntime fields allow for dynamic calculation of field values at search time, useful for complex calculations or when the field values are not stored.\nThe script in the runtime field calculates the discounted price by applying a 10% discount to the price field.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE product_index\n\n\n\nDocumentation\n\nCreate Index API\nBulk API\nIndex Document API\nRuntime Fields\n\n\n\n\nExample 2: Creating search queries for employees with a calculated total salary\nIn this example, the runtime field is defined as part of the index that executes code when documents are indexed. The salary field is read at index time to create a new value for the runtime field total_salary.\n\nRequirements\n\nAn index (employees) with documents containing employee information (name, department, salary)and a runtime field (total_salary) to calculate the total salary of each employee.\nA search query to retrieve employees with a total salary above $65,000.\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate the employees index with a mapping for the runtime field.\nPUT employees\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\"\n      },\n      \"department\": {\n        \"type\": \"text\"\n      },\n      \"salary\": {\n        \"type\": \"integer\"\n      },\n      \"total_salary\": {\n        \"type\": \"long\",\n        \"script\": {\n          \"source\": \"emit(doc['salary'].value * 12)\"\n        }\n      }\n    }\n  }\n}\nIndex some documents that contain a monthly salary.\nPOST /employees/_bulk\n{ \"index\": { \"_id\": \"1\" } }\n{ \"name\": \"John Doe\", \"department\": \"Sales\", \"salary\": 4000 }\n{ \"index\": { \"_id\": \"2\" } }\n{ \"name\": \"Jane Smith\", \"department\": \"Marketing\", \"salary\": 6000 }\n{ \"index\": { \"_id\": \"3\" } }\n{ \"name\": \"Bob Johnson\", \"department\": \"IT\", \"salary\": 7000 }\n{ \"index\": { \"_id\": \"4\" } }\n{ \"name\": \"Alice Brown\", \"department\": \"HR\", \"salary\": 5000 }\nExecute a search query with a runtime field.\nGET employees/_search\n{\n  \"query\": {\n    \"range\": {\n      \"total_salary\": {\n        \"gte\": 65000\n      }\n    }\n  },\n  \"fields\": [\n    \"total_salary\"\n  ]\n}\n\n\n\nTest\n\nVerify the creation of the index and its mappings.\nGET /employees\nVerify the indexed documents.\nGET /employees/_search\nExecute the query and verify the search results contain only employees with a total salary above 65000.\n{\n  ...\n    \"hits\": [\n      {\n        \"_index\": \"employees\",\n        \"_id\": \"2\",\n        \"_score\": 1,\n        \"_source\": {\n          \"name\": \"Jane Smith\",\n          \"department\": \"Marketing\",\n          \"salary\": 6000\n        },\n        \"fields\": {\n          \"total_salary\": [\n            72000\n          ]\n        }\n      },\n      {\n        \"_index\": \"employees\",\n        \"_id\": \"3\",\n        \"_score\": 1,\n        \"_source\": {\n          \"name\": \"Bob Johnson\",\n          \"department\": \"IT\",\n          \"salary\": 7000\n        },\n        \"fields\": {\n          \"total_salary\": [\n            84000\n          ]\n        }\n      }\n    ]\n  }\n}\n\n\n\nConsiderations\n\nRuntime fields are calculated on the fly and can be used in search queries, aggregations, and sorting.\nThe script used in the runtime field calculates the total salary by multiplying the monthly salary by 12 months.\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE employees\n\n\n\nDocumentation\n\nMap a Runtime Field\nScript Fields\n\n\n\n\nExample 3: Creating search queries with a runtime field for restaurant data\n\nRequirements\n\nCreate a search query for restaurants in New York City.\nInclude the restaurant’s name, cuisine, and a calculated rating_score in the search results.\n\nthe rating_score is calculated by taking the square root of the product of the review_score and number_of_reviews.\n\n\n\n\nSteps\n\nOpen the Kibana Console or use a REST client.\nCreate a restaurant index.\nPUT restaurants\n{\n  \"mappings\": {\n    \"properties\": {\n      \"city\": {\n        \"type\": \"keyword\"\n      },\n      \"cuisine\": {\n        \"type\": \"text\"\n      },\n      \"name\": {\n        \"type\": \"text\"\n      },\n      \"number_of_reviews\": {\n        \"type\": \"long\"\n      },\n      \"review_score\": {\n        \"type\": \"float\"\n      },\n      \"state\": {\n        \"type\": \"keyword\"\n      }\n    }\n  }\n}\nIndex some sample restaurant documents.\nPOST /restaurants/_bulk\n{ \"index\": { \"_id\": 1 } }\n{ \"name\": \"Tasty Bites\", \"city\": \"New York\", \"state\": \"NY\", \"cuisine\": \"Italian\", \"review_score\": 4.5, \"number_of_reviews\": 200 }\n{ \"index\": { \"_id\": 2 } }\n{ \"name\": \"Spicy Palace\", \"city\": \"Los Angeles\", \"state\": \"CA\", \"cuisine\": \"Indian\", \"review_score\": 4.2, \"number_of_reviews\": 150 }\n{ \"index\": { \"_id\": 3 } }\n{ \"name\": \"Sushi Spot\", \"city\": \"San Francisco\", \"state\": \"CA\", \"cuisine\": \"Japanese\", \"review_score\": 4.7, \"number_of_reviews\": 300 }\n{ \"index\": { \"_id\": 4 } }\n{ \"name\": \"Burger Joint\", \"city\": \"Chicago\", \"state\": \"IL\", \"cuisine\": \"American\", \"review_score\": 3.8, \"number_of_reviews\": 100 }\nCreate a query to return restaurants based from New York City.\nGET restaurants/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"city\": {\n              \"value\": \"New York\"\n            }\n          }\n        },\n        {\n          \"term\": {\n            \"state\": {\n              \"value\": \"NY\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\nDefine a runtime field named weighted_rating to calculate a weighted rating score for New York restaurants.\nGET restaurants/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"city\": {\n              \"value\": \"New York\"\n            }\n          }\n        },\n        {\n          \"term\": {\n            \"state\": {\n              \"value\": \"NY\"\n            }\n          }\n        }\n      ]\n    }\n  }, \n  \"runtime_mappings\": {\n    \"rating_score\": {\n      \"type\": \"double\",\n      \"script\": {\n        \"source\": \"emit(Math.sqrt(doc['review_score'].value * doc['number_of_reviews'].value))\"\n      }\n    }\n  },\n  \"fields\": [\n    \"rating_score\"\n  ]\n}\n\n\n\nTest\n\nVerify the creation of the index and its mappings.\nGET /restaurants\nVerify the indexed documents.\nGET /restaurants/_search\nExecute the query and verify the restaurant name, cuisine type, and the calculated weighted rating score for restaurants located in New York, NY.\n{\n  ...\n    \"hits\": [\n      {\n        \"_index\": \"restaurants\",\n        \"_id\": \"1\",\n        \"_score\": 2.4079456,\n        \"_source\": {\n          \"name\": \"Tasty Bites\",\n          \"city\": \"New York\",\n          \"state\": \"NY\",\n          \"cuisine\": \"Italian\",\n          \"review_score\": 4.5,\n          \"number_of_reviews\": 200\n        },\n        \"fields\": {\n          \"rating_score\": [\n            30\n          ]\n        }\n      }\n    ]\n  }\n}\n\n\n\nConsiderations\n\nThe runtime_mappings section defines a new field weighted_rating that calculates a weighted rating score based on the review_score and number_of_reviews fields.\nThe query section uses the term query to search for restaurants in New York, NY.\nThe fields section specifies the fields to include in the search results (in this case, the runtime field weighted_rating).\n\n\n\nClean-up (optional)\n\nDelete the index.\nDELETE restaurants\n\n\n\nDocumentation\n\nRuntime Fields in the Search Request",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Searching Data</span>"
    ]
  }
]